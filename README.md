Welcome to the GitHub repository for the paper titled "Towards a performance analysis on pre-trained Visual Question Answering models for autonomous driving." 

The supplementary material available in this GitHub repository includes:

Comprehensive corpus: A collection of 78 research papers on Visual Question Answering (VQA) models.
Test dataset: The dataset used for evaluating the three models analyzed in the paper (ViLBERT, ViLT, and LXMERT).
In-depth analysis: Detailed analysis of the results obtained from the evaluation of ViLBERT, ViLT, and LXMERT in the context of autonomous driving.

Feel free to access and utilize these resources to gain further insights and conduct additional research in the field of VQA for autonomous driving.
